{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Add a relevant banner image here](path_to_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Short project description. Your bottom line up front (BLUF) insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    EvalPrediction,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from evaluate import load\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"nileshmalode1/samsum-dataset-text-summarization\")\n",
    "\n",
    "print(\"Filepath to dataset: \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           dialogue  \\\n",
       "0  13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
       "1  13728867  Olivia: Who are you voting for in this electio...   \n",
       "2  13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n",
       "3  13730747  Edward: Rachel, I think I'm in ove with Bella....   \n",
       "4  13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n",
       "\n",
       "                                             summary  \n",
       "0  Amanda baked cookies and will bring Jerry some...  \n",
       "1  Olivia and Olivier are voting for liberals in ...  \n",
       "2  Kim may try the pomodoro technique recommended...  \n",
       "3  Edward thinks he is in love with Bella. Rachel...  \n",
       "4  Sam is confused, because he overheard Rick com...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samsum_train = pd.read_csv(\"Data/samsum-train.csv\")\n",
    "df_samsum_test = pd.read_csv(\"Data/samsum-test.csv\")\n",
    "df_samsum_val = pd.read_csv(\"Data/samsum-validation.csv\")\n",
    "\n",
    "df_samsum_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         diag_len\n",
       " count     14731.0\n",
       " mean   511.218315\n",
       " std    402.613071\n",
       " min          31.0\n",
       " 25%         216.5\n",
       " 50%         401.0\n",
       " 75%         694.0\n",
       " max        5492.0,\n",
       "          diag_len\n",
       " count       819.0\n",
       " mean   521.598291\n",
       " std    409.387325\n",
       " min          49.0\n",
       " 25%         226.0\n",
       " 50%         403.0\n",
       " 75%         687.5\n",
       " max        2793.0,\n",
       "          diag_len\n",
       " count       818.0\n",
       " mean   499.396088\n",
       " std    403.632584\n",
       " min          57.0\n",
       " 25%         208.0\n",
       " 50%         385.5\n",
       " 75%         688.0\n",
       " max        2950.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting all data into strings\n",
    "df_samsum_train['id'] = df_samsum_train['id'].astype('string')\n",
    "df_samsum_train['dialogue'] = df_samsum_train['dialogue'].astype('string')\n",
    "df_samsum_train['summary'] = df_samsum_train['summary'].astype('string')\n",
    "df_samsum_test['id'] = df_samsum_test['id'].astype('string')\n",
    "df_samsum_test['dialogue'] = df_samsum_test['dialogue'].astype('string')\n",
    "df_samsum_test['summary'] = df_samsum_test['summary'].astype('string')\n",
    "df_samsum_val['id'] = df_samsum_val['id'].astype('string')\n",
    "df_samsum_val['dialogue'] = df_samsum_val['dialogue'].astype('string')\n",
    "df_samsum_val['summary'] = df_samsum_val['summary'].astype('string')\n",
    "\n",
    "# adding a column to show length of strings in dialogue\n",
    "df_samsum_train['diag_len'] = df_samsum_train['dialogue'].str.len()\n",
    "df_samsum_test['diag_len'] = df_samsum_test['dialogue'].str.len()\n",
    "df_samsum_val['diag_len'] = df_samsum_val['dialogue'].str.len()\n",
    "\n",
    "df_samsum_train.describe(), df_samsum_test.describe(), df_samsum_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Falconsai tokenizer and creating TensorFlow datasets\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/text_summarization\")\n",
    "train_dataset = tokenizer(df_samsum_train['dialogue'].astype(str).tolist(), padding=True, truncation='longest_first', return_tensors=\"pt\")\n",
    "test_dataset = tokenizer(df_samsum_test['dialogue'].astype(str).tolist(), padding=True, truncation='longest_first', return_tensors=\"pt\")\n",
    "val_dataset = tokenizer(df_samsum_val['dialogue'].astype(str).tolist(), padding=True, truncation='longest_first', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Falconsai model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "class MetricsComputer:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.rouge = load('rouge')\n",
    "        \n",
    "    def compute_metrics(self, model_outputs, labels, loss=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_outputs: logits or generated token IDs from model\n",
    "            labels: reference summary token IDs\n",
    "            loss: precomputed loss value (optional)\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # 1. Loss (if provided)\n",
    "        if loss is not None:\n",
    "            metrics['loss'] = loss.item()\n",
    "        \n",
    "        # 2. Generate predictions (if logits provided)\n",
    "        if model_outputs.dim() == 3:  # logits shape: [batch, seq_len, vocab]\n",
    "            predictions = torch.argmax(model_outputs, dim=-1)\n",
    "        else:\n",
    "            predictions = model_outputs\n",
    "        \n",
    "        # 3. Decode to text\n",
    "        decoded_preds = self.tokenizer.batch_decode(\n",
    "            predictions, \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        decoded_labels = self.tokenizer.batch_decode(\n",
    "            labels, \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        # 4. Compute ROUGE scores\n",
    "        rouge_results = self.rouge.compute(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "            use_stemmer=True\n",
    "        )\n",
    "        \n",
    "        metrics.update({\n",
    "            'rouge1': rouge_results['rouge1'],\n",
    "            'rouge2': rouge_results['rouge2'],\n",
    "            'rougeL': rouge_results['rougeL']\n",
    "        })\n",
    "        \n",
    "        # 5. Token-level accuracy (optional)\n",
    "        if predictions.shape == labels.shape:\n",
    "            mask = labels != -100  # ignore padding\n",
    "            correct = (predictions == labels) & mask\n",
    "            metrics['token_accuracy'] = (correct.sum() / mask.sum()).item()\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Business Insight/Recommendation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau Dashboard link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "Text here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
